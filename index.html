<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <title>Loiacono streaming WebGPU</title>
  <style>
    body {
      font-family: system-ui, sans-serif;
      margin: 1.5rem;
      color: #111;
      background: #f6f6f6;
    }

    h1 {
      font-size: 1.6rem;
    }

    .controls {
      display: flex;
      gap: 0.75rem;
      align-items: center;
      margin-bottom: 1rem;
    }

    button {
      padding: 0.5rem 0.9rem;
      font-size: 1rem;
      border-radius: 0.35rem;
      border: 1px solid #666;
      background: white;
      cursor: pointer;
    }

    button:disabled {
      opacity: 0.3;
      cursor: not-allowed;
    }

    .file-upload {
      display: flex;
      gap: 0.4rem;
      align-items: center;
      font-size: 0.9rem;
      color: #333;
    }

    .file-upload input {
      cursor: pointer;
    }

    .toggle-control {
      display: inline-flex;
      align-items: center;
      gap: 0.3rem;
      font-size: 0.9rem;
      color: #222;
      margin-left: 0.5rem;
    }

    .toggle-control input {
      cursor: pointer;
    }

    canvas {
      display: block;
      margin-top: 1rem;
      border-radius: 0.35rem;
      border: 1px solid #ccc;
      background: #111;
    }

    #status {
      font-weight: bold;
    }

    #stats {
      margin-top: 0.75rem;
      font-size: 0.9rem;
      color: #444;
      background: white;
      border-radius: 0.35rem;
      padding: 0.5rem;
      border: 1px solid #ddd;
    }
  </style>
</head>

<body>
  <h1>Streaming Loiacono Spectrogram (WebGPU)</h1>
  <div class="controls">
    <button id="startBtn">Start streaming</button>
    <button id="stopBtn" disabled>Stop</button>
    <label class="file-upload">
      Upload audio file
      <input id="audioFileInput" type="file" accept="audio/*" />
    </label>
    <label class="toggle-control">
      <input type="checkbox" id="singleChunkMode" checked />
      Single-chunk queue (debug)
    </label>
    <label class="toggle-control">
      <input type="checkbox" id="pixelPerfectMode" checked />
      Pixel-perfect (1:1) rendering
    </label>
    <span id="status">idle</span>
  </div>
  <canvas id="spectrumCanvas" width="900" height="320"></canvas>
  <pre id="stats">waiting for audio...</pre>

  <script type="module">
    const SIGNAL_LENGTH = 8192;
    const NUM_BINS = 512;
    const CHUNK_SIZE = 256;
    const WORKGROUP_SIZE = 64;
    const MULTIPLE = 15.0;
    const MIN_FREQ = 100.0;
    const MAX_FREQ = 12000.0;
    const DEFAULT_SR = 48000;
    let sampleRate = DEFAULT_SR;

    const statusEl = document.getElementById("status");
    const statsEl = document.getElementById("stats");
    const canvas = document.getElementById("spectrumCanvas");
    const ctx = canvas.getContext("2d", { willReadFrequently: true });
    const singleChunkCheckbox = document.getElementById("singleChunkMode");
    const pixelPerfectCheckbox = document.getElementById("pixelPerfectMode");
    let width = canvas.width;
    let height = canvas.height;
    
    // Spectrogram parameters
    let SPECTROGRAM_WIDTH = width;
    const SPECTROGRAM_HEIGHT = NUM_BINS;
    let spectrogramHistory = [];
    let MAX_HISTORY = Math.max(1, Math.floor(width)); // One column per pixel
    let spectrogramImageData = null;
    let spectrogramCanvas = null;
    let spectrogramCtx = null;
    
    function syncCanvasSize() {
      const rect = canvas.getBoundingClientRect();
      const targetWidth = Math.max(1, Math.floor(rect.width));
      const targetHeight = Math.max(1, Math.floor(rect.height));
      if (pixelPerfectCheckbox && pixelPerfectCheckbox.checked) {
        canvas.style.width = `${targetWidth}px`;
        canvas.style.height = `${targetHeight}px`;
      } else {
        canvas.style.width = "";
        canvas.style.height = "";
      }
      if (canvas.width !== targetWidth || canvas.height !== targetHeight) {
        canvas.width = targetWidth;
        canvas.height = targetHeight;
      }
      width = canvas.width;
      height = canvas.height;
      SPECTROGRAM_WIDTH = width;
      MAX_HISTORY = Math.max(1, Math.floor(width));
    }

    // Initialize spectrogram
    function initSpectrogram() {
      spectrogramHistory = [];
      spectrogramCanvas = document.createElement('canvas');
      spectrogramCanvas.width = SPECTROGRAM_WIDTH;
      spectrogramCanvas.height = SPECTROGRAM_HEIGHT;
      spectrogramCtx = spectrogramCanvas.getContext('2d');
      spectrogramImageData = spectrogramCtx.createImageData(SPECTROGRAM_WIDTH, SPECTROGRAM_HEIGHT);
      // Fill with black
      for (let i = 0; i < spectrogramImageData.data.length; i += 4) {
        spectrogramImageData.data[i] = 0;     // R
        spectrogramImageData.data[i + 1] = 0; // G
        spectrogramImageData.data[i + 2] = 0; // B
        spectrogramImageData.data[i + 3] = 255; // A
      }
      spectrogramCtx.putImageData(spectrogramImageData, 0, 0);
    }
    
    // Viridis colormap (simplified)
    function viridisColor(t) {
      // t should be between 0 and 1
      const t2 = t * t;
      const t3 = t2 * t;
      // Simplified viridis approximation
      const r = Math.min(255, Math.max(0, Math.floor(255 * (0.2627 + t * 1.8811 - t2 * 2.8294 + t3 * 2.4889))));
      const g = Math.min(255, Math.max(0, Math.floor(255 * (0.1949 + t * 2.0312 - t2 * 3.3897 + t3 * 2.8606))));
      const b = Math.min(255, Math.max(0, Math.floor(255 * (0.3484 + t * 3.5947 - t2 * 6.2286 + t3 * 4.6983))));
      return [r, g, b];
    }
    
    // Convert magnitude to color using log scaling
    function magnitudeToColor(magnitude, maxMagnitude) {
      if (magnitude <= 0) return [0, 0, 0];
      // Log scale for better dynamic range
      const logVal = Math.log10(magnitude + 1) / Math.log10(maxMagnitude + 1);
      return viridisColor(Math.min(1, logVal));
    }

    let device;
    let queue;
    let pipeline;
    let bindGroup;
    let chunkBuffer;
    let chunkRealBuffer;
    let chunkImagBuffer;
    let freqBuffer;
    let paramsBuffer;
    let stagingBuffer;

    let adapter;
    let audioCtx;
    let audioNode;
    let mediaStream;
    let running = false;

    let pendingChunk = new Float32Array(CHUNK_SIZE);
    let pendingCount = 0;
    const WINDOW_CHUNKS = SIGNAL_LENGTH / CHUNK_SIZE;
    let processedChunks = 0;
    let totalSamplesCaptured = 0;
    const chunkQueue = [];
    let queueProcessing = false;
    let currentReal = new Float32Array(NUM_BINS);
    let currentImag = new Float32Array(NUM_BINS);
    const chunkHistory = Array.from({ length: WINDOW_CHUNKS }, () => ({
      real: new Float32Array(NUM_BINS),
      imag: new Float32Array(NUM_BINS),
    }));

    function getChunkQueueLimit() {
      if (singleChunkCheckbox && singleChunkCheckbox.checked) {
        return 1;
      }
      return Math.max(8, WINDOW_CHUNKS * 2);
    }

    window.addEventListener("resize", () => {
      syncCanvasSize();
      initSpectrogram();
      resetHistory();
    });

    const shaderPath = "shaders/loiacono_stream.wgsl";
    const fileInput = document.getElementById("audioFileInput");
    fileInput.addEventListener("change", handleFileUpload);
    singleChunkCheckbox.addEventListener("change", () => {
      chunkQueue.length = 0;
    });
    pixelPerfectCheckbox.addEventListener("change", () => {
      syncCanvasSize();
      initSpectrogram();
      resetHistory();
    });

    document.getElementById("startBtn").addEventListener("click", startStreaming);
    document.getElementById("stopBtn").addEventListener("click", stopStreaming);

    function resetHistory() {
      currentReal.fill(0);
      currentImag.fill(0);
      chunkHistory.forEach((entry) => {
        entry.real.fill(0);
        entry.imag.fill(0);
      });
      processedChunks = 0;
      totalSamplesCaptured = 0;
      chunkQueue.length = 0;
      queueProcessing = false;
      pendingChunk.fill(0);
      pendingCount = 0;
    }

    async function startStreaming() {
      if (running) {
        return;
      }
      running = true;
      document.getElementById("startBtn").disabled = true;
      document.getElementById("stopBtn").disabled = false;
      statusEl.textContent = "initializing GPU & microphone...";

      resetHistory();
      try {
        await ensureGpu();
        await ensureAudio();
        statusEl.textContent = "listening to microphone…";
        statsEl.textContent = "collecting first chunk...";
      } catch (error) {
        statusEl.textContent = `error: ${error.message}`;
        running = false;
        document.getElementById("startBtn").disabled = false;
        document.getElementById("stopBtn").disabled = true;
      }
    }

    async function stopStreaming() {
      running = false;
      document.getElementById("startBtn").disabled = false;
      document.getElementById("stopBtn").disabled = true;
      statusEl.textContent = "stopped";
      statsEl.textContent = "idle";
      if (audioNode) {
        audioNode.disconnect();
        // Clear event handlers
        if (audioNode.onaudioprocess) {
          audioNode.onaudioprocess = null;
        }
        if (audioNode.port && audioNode.port.onmessage) {
          audioNode.port.onmessage = null;
        }
        audioNode = null;
      }
      if (audioCtx) {
        audioCtx.close();
        audioCtx = null;
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach((track) => track.stop());
        mediaStream = null;
      }
      pendingCount = 0;
    }

    async function handleFileUpload(event) {
      const file = event.target?.files?.[0];
      if (!file) {
        return;
      }
      if (running) {
        stopStreaming();
      }
      try {
        await ensureGpu();
        await decodeAndStreamAudio(await file.arrayBuffer(), file.name);
      } catch (error) {
        statusEl.textContent = `file error: ${error.message}`;
        console.error(error);
      }
    }

    function mixToMono(buffer) {
      const channels = buffer.numberOfChannels;
      const length = buffer.length;
      const output = new Float32Array(length);
      for (let c = 0; c < channels; c++) {
        const channelData = buffer.getChannelData(c);
        for (let i = 0; i < length; i++) {
          output[i] += channelData[i];
        }
      }
      if (channels > 1) {
        const factor = 1 / channels;
        for (let i = 0; i < length; i++) {
          output[i] *= factor;
        }
      }
      return output;
    }

    async function streamUploadedSamples(samples, options = {}) {
      const { singleChunkMode = false } = options;
      statsEl.textContent = `playing uploaded audio (${samples.length} samples)…`;
      let offset = 0;
      while (offset < samples.length) {
        const end = Math.min(samples.length, offset + CHUNK_SIZE);
        feedSamples(samples.subarray(offset, end));
        offset = end;
        if (singleChunkMode) {
          await waitForQueueIdle();
        } else {
          await new Promise((resolve) => setTimeout(resolve, 0));
        }
      }
      if (pendingCount > 0) {
        const padding = new Float32Array(CHUNK_SIZE - pendingCount);
        feedSamples(padding);
      }
      await waitForQueueIdle();
    }

    async function decodeAndStreamAudio(arrayBuffer, label) {
      statusEl.textContent = `decoding ${label}…`;
      const decodeCtx = new AudioContext();
      const audioBuffer = await decodeCtx.decodeAudioData(arrayBuffer);
      await decodeCtx.close();
      if (audioBuffer.length === 0) {
        throw new Error("decoded buffer is empty");
      }
      if (audioBuffer.sampleRate !== sampleRate) {
        sampleRate = audioBuffer.sampleRate;
        updateFrequencyBuffer(sampleRate);
      }
      resetHistory();
      await streamUploadedSamples(mixToMono(audioBuffer), {
        singleChunkMode: singleChunkCheckbox?.checked,
      });
      statusEl.textContent = `processed ${label}`;
    }

    async function ensureGpu() {
      if (device) {
        return;
      }
      if (!navigator.gpu) {
        throw new Error("WebGPU is not supported in this browser.");
      }
      adapter = await navigator.gpu.requestAdapter();
      if (!adapter) {
        throw new Error("Failed to request a GPU adapter.");
      }
      device = await adapter.requestDevice();
      queue = device.queue;
      syncCanvasSize();
      initSpectrogram(); // Initialize spectrogram
      await setupPipeline();
    }

    async function setupPipeline() {
      const shaderReq = await fetch(shaderPath);
      if (!shaderReq.ok) {
        throw new Error(`Failed to load shader: ${shaderPath} (${shaderReq.status})`);
      }
      const shaderText = await shaderReq.text();
      const module = device.createShaderModule({ code: shaderText });
      pipeline = device.createComputePipeline({
        layout: "auto",
        compute: { module, entryPoint: "main" },
      });

      chunkBuffer = device.createBuffer({
        size: CHUNK_SIZE * 4,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      chunkRealBuffer = device.createBuffer({
        size: NUM_BINS * 4,
        usage:
          GPUBufferUsage.STORAGE |
          GPUBufferUsage.COPY_SRC |
          GPUBufferUsage.COPY_DST,
      });
      chunkImagBuffer = device.createBuffer({
        size: NUM_BINS * 4,
        usage:
          GPUBufferUsage.STORAGE |
          GPUBufferUsage.COPY_SRC |
          GPUBufferUsage.COPY_DST,
      });
      freqBuffer = device.createBuffer({
        size: NUM_BINS * 4,
        usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
      });
      paramsBuffer = device.createBuffer({
        size: 16,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
      });
      stagingBuffer = device.createBuffer({
        size: NUM_BINS * 4 * 2,
        usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,
      });

      const freqs = buildFrequencyArray(sampleRate);
      queue.writeBuffer(freqBuffer, 0, freqs.buffer, freqs.byteOffset, freqs.byteLength);

      bindGroup = device.createBindGroup({
        layout: pipeline.getBindGroupLayout(0),
        entries: [
          { binding: 0, resource: { buffer: chunkBuffer } },
          { binding: 1, resource: { buffer: chunkRealBuffer } },
          { binding: 2, resource: { buffer: chunkImagBuffer } },
          { binding: 3, resource: { buffer: freqBuffer } },
          { binding: 4, resource: { buffer: paramsBuffer } },
        ],
      });
    }

    async function ensureAudio() {
      audioCtx = new AudioContext();
      sampleRate = audioCtx.sampleRate;
      updateFrequencyBuffer(sampleRate);
      
      // Try to use AudioWorklet if supported, fall back to ScriptProcessorNode
      if (audioCtx.audioWorklet && typeof AudioWorkletNode === 'function') {
        try {
          // Load and add the audio worklet module
          await audioCtx.audioWorklet.addModule('audio-processor.js');
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          const source = audioCtx.createMediaStreamSource(mediaStream);
          audioNode = new AudioWorkletNode(audioCtx, 'audio-stream-processor');
          
          audioNode.port.onmessage = (event) => {
            if (event.data.type === 'audioData') {
              feedSamples(event.data.data);
            }
          };
          
          source.connect(audioNode);
          audioNode.connect(audioCtx.destination);
          return;
        } catch (error) {
          console.warn('AudioWorklet failed, falling back to ScriptProcessorNode:', error);
          // Fall through to ScriptProcessorNode implementation
        }
      }
      
      // Fallback to ScriptProcessorNode (deprecated but works)
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const source = audioCtx.createMediaStreamSource(mediaStream);
      audioNode = audioCtx.createScriptProcessor(512, 1, 1);
      source.connect(audioNode);
      audioNode.connect(audioCtx.destination);
      audioNode.onaudioprocess = (event) => {
        const input = event.inputBuffer.getChannelData(0);
        feedSamples(input);
      };
    }

    function feedSamples(samples) {
      let offset = 0;
      while (offset < samples.length) {
        const need = CHUNK_SIZE - pendingCount;
        const copyLen = Math.min(need, samples.length - offset);
        pendingChunk.set(samples.subarray(offset, offset + copyLen), pendingCount);
        pendingCount += copyLen;
        offset += copyLen;
        totalSamplesCaptured += copyLen;

        if (pendingCount === CHUNK_SIZE) {
          const chunkData = pendingChunk.slice();
          const chunkStart = Math.max(0, totalSamplesCaptured - CHUNK_SIZE);
          chunkQueue.push({ data: chunkData, start: chunkStart });
          console.debug("queued chunk", chunkQueue.length, chunkStart);
          const queueLimit = getChunkQueueLimit();
          if (chunkQueue.length > queueLimit) {
            chunkQueue.shift();
          }
          pendingCount = 0;
          processChunkQueue();
        }
      }
    }

    function processChunkQueue() {
      if (queueProcessing) {
        return;
      }
      queueProcessing = true;
      (async () => {
        try {
          while (chunkQueue.length > 0) {
            const { data, start } = chunkQueue.shift();
            console.debug("dispatch chunk", start, "queue len", chunkQueue.length);
            await runChunk(data, CHUNK_SIZE, start, processedChunks);
            processedChunks += 1;
          }
        } finally {
          queueProcessing = false;
        }
      })();
    }

    function waitForQueueIdle() {
      return new Promise((resolve) => {
        const check = () => {
          if (!queueProcessing && chunkQueue.length === 0) {
            resolve();
          } else {
            setTimeout(check, 10);
          }
        };
        check();
      });
    }

    async function runChunk(chunkData, length, chunkStart, chunkIndex) {
      queue.writeBuffer(chunkBuffer, 0, chunkData.buffer, 0, CHUNK_SIZE * 4);
      const params = new Uint32Array([chunkStart >>> 0, length, 0, 0]);
      queue.writeBuffer(paramsBuffer, 0, params.buffer, params.byteOffset, params.byteLength);

      const encoder = device.createCommandEncoder();
      const pass = encoder.beginComputePass();
      pass.setPipeline(pipeline);
      pass.setBindGroup(0, bindGroup);
      pass.dispatchWorkgroups(Math.ceil(NUM_BINS / WORKGROUP_SIZE));
      pass.end();

      encoder.copyBufferToBuffer(
        chunkRealBuffer,
        0,
        stagingBuffer,
        0,
        NUM_BINS * 4
      );
      encoder.copyBufferToBuffer(
        chunkImagBuffer,
        0,
        stagingBuffer,
        NUM_BINS * 4,
        NUM_BINS * 4
      );
      queue.submit([encoder.finish()]);

      await stagingBuffer.mapAsync(GPUMapMode.READ);
      const mapped = stagingBuffer.getMappedRange(0, NUM_BINS * 4 * 2);
      const realChunk = new Float32Array(mapped, 0, NUM_BINS);
      const imagChunk = new Float32Array(
        mapped,
        NUM_BINS * 4,
        NUM_BINS
      );
      const realData = new Float32Array(realChunk);
      const imagData = new Float32Array(imagChunk);
      stagingBuffer.unmap();

      const historySlot = chunkHistory[chunkIndex % WINDOW_CHUNKS];
      if (chunkIndex >= WINDOW_CHUNKS) {
        const oldReal = historySlot.real;
        const oldImag = historySlot.imag;
        for (let i = 0; i < NUM_BINS; ++i) {
          currentReal[i] -= oldReal[i];
          currentImag[i] -= oldImag[i];
        }
      }
      historySlot.real.set(realData);
      historySlot.imag.set(imagData);
      for (let i = 0; i < NUM_BINS; ++i) {
        currentReal[i] += realData[i];
        currentImag[i] += imagData[i];
      }

      const magnitudes = new Float32Array(NUM_BINS);
      for (let i = 0; i < NUM_BINS; ++i) {
        magnitudes[i] = Math.sqrt(
          currentReal[i] * currentReal[i] + currentImag[i] * currentImag[i]
        );
      }
      drawSpectrum(magnitudes, chunkIndex);

    }

    function drawSpectrum(data, chunkIndex) {
      // Add new spectrum to history
      spectrogramHistory.push(data);
      if (spectrogramHistory.length > MAX_HISTORY) {
        spectrogramHistory.shift(); // Remove oldest
      }

      // Find global maximum for color mapping
      let globalMax = 0;
      for (const spectrum of spectrogramHistory) {
        const maxInSpectrum = Math.max(...spectrum);
        if (maxInSpectrum > globalMax) {
          globalMax = maxInSpectrum;
        }
      }

      // Shift existing spectrogram pixels left by one column using drawImage (correct row-major layout)
      if (SPECTROGRAM_WIDTH > 1) {
        // Disable smoothing to keep 1-px columns crisp
        spectrogramCtx.imageSmoothingEnabled = false;
        // Shift everything right by one pixel so new data appears on the left
        spectrogramCtx.drawImage(spectrogramCanvas, 1, 0);
      }

      // Fill the leftmost column with the latest spectrum (left-to-right sweep)
      const latestSpectrum = spectrogramHistory[spectrogramHistory.length - 1];
      for (let y = 0; y < SPECTROGRAM_HEIGHT; y++) {
        // Use SPECTROGRAM_HEIGHT - 1 - y so low frequencies are at the bottom
        const binIndex = SPECTROGRAM_HEIGHT - 1 - y;
        const magnitude = latestSpectrum[binIndex];
        const [r, g, b] = magnitudeToColor(magnitude, globalMax || 1);
        spectrogramCtx.fillStyle = `rgb(${r},${g},${b})`;
        spectrogramCtx.fillRect(0, y, 1, 1);
      }

      // Draw spectrogram to main canvas (scaled to fit)
      ctx.fillStyle = "#111";
      ctx.fillRect(0, 0, width, height);
      ctx.imageSmoothingEnabled = false;
      ctx.drawImage(spectrogramCanvas, 0, 0, width, height);
      
      // Update stats with magnitude info
      const currentMax = Math.max(...latestSpectrum);
      statsEl.textContent = `Spectrogram: ${spectrogramHistory.length} cols, chunk #${chunkIndex}, Global max: ${globalMax.toFixed(
        4
      )}, Current max: ${currentMax.toFixed(4)}`;
      console.debug("draw chunk", chunkIndex, "max", currentMax);
    }

    async function autoplayChirp() {
      try {
        await ensureGpu();
        const response = await fetch("chirp.wav");
        if (!response.ok) {
          throw new Error("Failed to fetch chirp.wav");
        }
        console.debug("chirp fetch status", response.status);
        await decodeAndStreamAudio(await response.arrayBuffer(), "chirp.wav");
      } catch (error) {
        console.warn("Chirp auto-run failed:", error);
      }
    }

    autoplayChirp();

    function buildFrequencyArray(rate) {
      const freqs = new Float32Array(NUM_BINS);
      const minNorm = MIN_FREQ / rate;
      const maxNorm = MAX_FREQ / rate;
      const logMin = Math.log(minNorm);
      const logMax = Math.log(maxNorm);
      const delta = logMax - logMin;
      for (let i = 0; i < NUM_BINS; ++i) {
        const ratio = i / (NUM_BINS - 1);
        freqs[i] = Math.exp(logMin + delta * ratio);
      }
      return freqs;
    }

    function updateFrequencyBuffer(rate) {
      if (!freqBuffer) {
        return;
      }
      const freqs = buildFrequencyArray(rate);
      queue.writeBuffer(freqBuffer, 0, freqs.buffer, freqs.byteOffset, freqs.byteLength);
    }
  </script>
</body>

</html>
